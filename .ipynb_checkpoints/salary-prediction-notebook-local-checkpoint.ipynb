{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary Predictions Based on Job Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 1 Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the known salary for a big set of Job ID listings along with some known (relevant) features, i.e. Company ID, Job Type, Degree, Major, Industry, Years Experience, and Distance from Metropolitan, we would would like to develop a machine learned statistical model to predict the salary for another dataset of Job ID postings with the same features as the ones for jobs having known salaries. In other words, we train our model based on the Job ID dataset with known salaries and, then, test it on the Job ID dataset with unknown salaries. This is a supervised machine learning problem for lots of applications like glassdoor in order to predict salary for any given Job ID, e.g. position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the neccessary modules for data manipulation, visual representation, and machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from scipy.stats import *\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler  \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "\n",
    "from xgboost import XGBRegressor \n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# author's contact information\n",
    "__author__ = \"Ashoordin Ashoormaram\"\n",
    "__email__ = \"a.ashoormaram@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 2 Load the data ----\n",
    "Importing the data into a Pandas dataframe making sure it is updated on a daily basis if applicable for the corresponding business problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data\n",
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_salaries = pd.read_csv('data/train_salaries.csv')\n",
    "\n",
    "#testing data\n",
    "test = pd.read_csv('data/test_features.csv')\n",
    "\n",
    "#merge features and salaries of the train dataset\n",
    "train = pd.merge(train_features, train_salaries, on='jobId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 3 Clean the data ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see if there is any missing data in the dataset. Check the type of our features. Are there any data inconsistencies? Check to see if there are any missing values in our dataset. Check for duplicate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000000 entries, 0 to 999999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count    Dtype \n",
      "---  ------               --------------    ----- \n",
      " 0   jobId                1000000 non-null  object\n",
      " 1   companyId            1000000 non-null  object\n",
      " 2   jobType              1000000 non-null  object\n",
      " 3   degree               1000000 non-null  object\n",
      " 4   major                1000000 non-null  object\n",
      " 5   industry             1000000 non-null  object\n",
      " 6   yearsExperience      1000000 non-null  int64 \n",
      " 7   milesFromMetropolis  1000000 non-null  int64 \n",
      " 8   salary               1000000 non-null  int64 \n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 76.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "jobId                  object\n",
       "companyId              object\n",
       "jobType                object\n",
       "degree                 object\n",
       "major                  object\n",
       "industry               object\n",
       "yearsExperience         int64\n",
       "milesFromMetropolis     int64\n",
       "salary                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "jobId                  False\n",
       "companyId              False\n",
       "jobType                False\n",
       "degree                 False\n",
       "major                  False\n",
       "industry               False\n",
       "yearsExperience        False\n",
       "milesFromMetropolis    False\n",
       "salary                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dropna().info()\n",
    "train.dtypes\n",
    "train.isnull().any()\n",
    "train.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for invalid data (salaries <=0), (milesFromMetropolis <0), and (yearsExperience <0). If there is, get names of indexes of the corresponding column features and delete those rows if they are few in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_salary = sum(n <= 0 for n in train.salary)\n",
    "print(\"invalid_salary:\", invalid_salary)\n",
    "\n",
    "invalid_milesFromMetropolis = sum(n < 0 for n in train.milesFromMetropolis)\n",
    "print(\"invalid_milesFromMetropolis:\", invalid_milesFromMetropolis)\n",
    "\n",
    "invalid_yearsExperience = sum(n < 0 for n in train.yearsExperience)\n",
    "print(\"invalid_yearsExperience:\", invalid_yearsExperience)\n",
    "\n",
    "train.query('salary == %d' %0)\n",
    "indexNames = train[ train['salary'] == 0 ].index\n",
    "train.drop(indexNames, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 4 Explore the data (EDA) ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize each feature variable, the target variable, look for correlation between each feature and the target as well as the correlation between features through the following actions: \n",
    "\n",
    "* The total number (and individual distinc values) for each variable and independent variable, \n",
    "* Summarize the statistical description of target, \"salary,\" for each feature, and \n",
    "* The fraction of the \"NONE\" values for any feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.nunique()\n",
    "\n",
    "def unique_values(col):\n",
    "    print('unique values: {}\\n'.format(train[col].unique()))\n",
    "        \n",
    "def salary_statistics_by_feature(col):\n",
    "    with pd.option_context('display.colheader_justify','left'):\n",
    "        print('{}'.format(train.groupby(col)['salary'].describe()))\n",
    "        \n",
    "def NONE_values_by_feature(col):\n",
    "    print('No. of NONE values: {}'.format(sum(n=='NONE' for n in train[col].values)))\n",
    "\n",
    "train_features = ['companyId', 'jobType', 'degree', 'major', \n",
    "                  'industry', 'yearsExperience', 'milesFromMetropolis', 'salary']  \n",
    "for col in train_features:\n",
    "    print('\\n\\n\\n\\033[1m{}:\\033[0m'.format(col))\n",
    "    NONE_values_by_feature(col)\n",
    "    unique_values(col)\n",
    "    salary_statistics_by_feature(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer the following questions:\n",
    "* What features correlate the most with salary?\n",
    "* What other correlations did you find?\n",
    "* Make sure to specify some features that you might want to focus on or the plots might be too big\n",
    "\n",
    "Let's plot Box and Whisker Plots of numerical features, the correlation between the 'salary' and all the other features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ashoordin)\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 15}         \n",
    "mpl.rc('font', **font) #set the font style created\n",
    "\n",
    "# bar plots of individual columns\n",
    "for col in train_features:\n",
    "    if col != 'salary':\n",
    "        feature_barplot = train[col].value_counts().plot(kind='bar', fontsize=10, \n",
    "                                                         xlabel=col , ylabel='salary' , figsize=(20,3))\n",
    "        plt.show()\n",
    "    else:\n",
    "        feature_histogram = train.salary.hist(bins=25, xlabelsize=20, ylabelsize=20, \n",
    "                                              xlabel='salary' , ylabel='Frequency', figsize=(5,5))\n",
    "        plt.show()\n",
    "\n",
    "# distribution of numerical variables across all data\n",
    "num_var_dist = train.plot(kind='box', subplots=True, layout=(1,3), sharex=False, sharey=False, \n",
    "                          figsize=(20,5), rot=90, vert=False)\n",
    "plt.show()\n",
    "\n",
    "# distribution of dependent variable grouped by category\n",
    "for col in train_features[1:-1]:\n",
    "    if col not in ['yearsExperience', 'milesFromMetropolis']:\n",
    "        target_dist = sns.boxplot(x=\"salary\", y=col, data=train)\n",
    "        plt.show()\n",
    "    else:\n",
    "        target_scat = sns.scatterplot(x=\"salary\", y=col, data=train)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like \"jobId\", \"companyId\" has no affect on the predictions of salaries. So, I could safely remove them in order to reduce the possible number of categorical features to make a more simple modle for a lower computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both \"train\" and \"test\" datasets, **object** must be converted into **categorical** data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.copy()\n",
    "for col in ['jobId', 'companyId', 'jobType', 'degree', 'major', 'industry']:\n",
    "    train_data[col] = train_data[col].astype('category')\n",
    "\n",
    "# turn 'objects' into 'categoricals' for test dataset\n",
    "test_data = test.copy()\n",
    "for col in ['jobId', 'companyId', 'jobType', 'degree', 'major', 'industry']:\n",
    "    test_data[col] = test_data[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* categorical features:\n",
    "    'jobType', 'degree', 'major', 'industry'\n",
    "\n",
    "    * ordinal: \n",
    "    \"jobType\", \"degree\" \n",
    "    \n",
    "    * onehot: \n",
    "    \"major\", \"industry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "train_data = train_data.drop(['jobId', 'companyId'], axis=1)\n",
    "train_data_NonEngineered = train_data.copy()\n",
    "\n",
    "# replace ordinal categorical features in place\n",
    "replace_map = {'degree': {'NONE': 1, 'HIGH_SCHOOL': 2, 'BACHELORS': 3, 'MASTERS': 4, 'DOCTORAL': 5}, \n",
    "               'jobType': {'JANITOR':1, 'JUNIOR':2, 'SENIOR':3, 'MANAGER':4, 'VICE_PRESIDENT':5, 'CFO':6, 'CTO':7, 'CEO':8}\n",
    "              }\n",
    "              #'major': {'MATH': 1, 'NONE':2, 'PHYSICS':3, 'CHEMISTRY':4, 'COMPSCI':5, 'BIOLOGY':6, 'LITERATURE':7, 'BUSINESS':8, 'ENGINEERING':9}, 'industry': {'HEALTH':1, 'WEB':2, 'AUTO':3, 'FINANCE':4, 'EDUCATION':5, 'OIL':6, 'SERVICE':7}\n",
    "train_data_NonEngineered.replace(replace_map, inplace=True)\n",
    "\n",
    "\n",
    "#train_data_NonEngineered = train_data_NonEngineered.copy()\n",
    "# generate binary values using get_dummies to onehot encode the non-ordinal categorical features\n",
    "train_data_Engineered = pd.get_dummies(train_data_NonEngineered)  \n",
    "\n",
    "#taking salary \"target\" to the end of table\n",
    "columnsName = list(train_data_Engineered.columns)\n",
    "salary, last = columnsName.index('salary'), columnsName.index(columnsName[-1])\n",
    "columnsName[salary], columnsName[last] = columnsName[last],columnsName[salary]\n",
    "train_data_Engineered = train_data_Engineered[columnsName]\n",
    "\n",
    "# Test Dataset\n",
    "test_data = test_data.drop(['jobId', 'companyId'], axis=1)\n",
    "test_data_NonEngineered = test_data.copy()\n",
    "test_data_NonEngineered.replace(replace_map, inplace=True)\n",
    "test_data_NonEngineered = test_data_NonEngineered.copy()\n",
    "\n",
    "# generate binary values using get_dummies to onehot encode \n",
    "# the non-ordinal categorical features\n",
    "test_data_Engineered = pd.get_dummies(test_data_NonEngineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the the final \"train\" and \"test\" data after feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_Engineered.tail()\n",
    "test_data_Engineered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce memory usage according to the [Kaggle](https://www.kaggle.com/gemartin/load-data-reduce-memory-usage) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import reduce_mem_usage as rmu\n",
    "train_data_Engineered = rmu.reduce_mem_usage(train_data_Engineered)\n",
    "test_data_Engineered = rmu.reduce_mem_usage(test_data_Engineered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's observe the mutual correlatin among features and target variables in order to establish a baseline model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = train_data_NonEngineered[['jobType', 'degree', 'yearsExperience', 'milesFromMetropolis', 'salary']].corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.set(font_scale=1.5)\n",
    "    f, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax = sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values, \n",
    "            yticklabels=corr.columns.values,\n",
    "            vmin=-1, vmax=1, center= 0, square=True, cmap= 'coolwarm', \n",
    "            annot = True, mask=mask, fmt='0.4f', annot_kws= {'size': 22}\n",
    "                    )\n",
    "    \n",
    "    my_title = ax.set_title('Heatmap of Correlation Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 5 Establish a baseline ----\n",
    "We are assuming that the only feature that will determine the salary is \"industry\". Given the complexity of the problem where salary actually depends on all features (except \"jobId\" and \"companyId\") and that most of them are categoricals, in this baseline, we can ignore all but \"industry\" and then assign _mean_ value of each individual \"industry\" to all rows having that same \"industry\". The reasonable metric to select in this case is _mean squared error (MSE)_ since the problem is a *_regression_* one where the _numerical, continuous_ target depends on a set of features. I measured the efficacy of this simplistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import baseline_algorithm_regression as baseline\n",
    "baseline.baseline_algorithm_regression(train_data, 'salary', 'industry', test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split-out \"train\" dataset into \"train\" and \"validation\" subsets and create some initial models based on the reduced version of \"train\" dataset where \"jobId\" and \"companyId\" are removed and all categorical features are encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_Engineered.values\n",
    "n_features = len(train_data_Engineered.columns)-1\n",
    "salary_features = data[:,:n_features] \n",
    "salary_target = data[:,n_features]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "\n",
    "features_train, features_validation, target_train, target_validation = train_test_split(\n",
    "    salary_features, salary_target, test_size=validation_size, random_state=seed)\n",
    "\n",
    "# Create model shells  \n",
    "models = []\n",
    "models.append(('knr', KNeighborsRegressor()))\n",
    "models.append(('linreg', LinearRegression()))\n",
    "models.append(('ridge', Ridge()))\n",
    "models.append(('lasso', Lasso()))\n",
    "models.append(('dtr', DecisionTreeRegressor()))\n",
    "models.append(('gbr', GradientBoostingRegressor()))\n",
    "models.append(('xgbr', XGBRegressor()))\n",
    "models.append(('rfr', RandomForestRegressor(n_estimators=10, max_depth=5)))\n",
    "\n",
    "# Spot test each model with Cross-validation evaluating each model in turn\n",
    "results, names = [], []\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "for name, model in models:\n",
    "    cv_results = cross_val_score(model, features_train, target_train, cv=kfold, \n",
    "                                 scoring='neg_mean_squared_error', n_jobs=-1)  \n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('{}: {:.1f} ({:.1f})'.format(name, -1*cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "# Graphical comparison of algorithms\n",
    "fig = plt.figure()\n",
    "my_subtitle = fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "my_boxplot = plt.boxplot(results)\n",
    "my_xticklabels = ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 6 Hypothesize solution ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Algorithms I considered were, **_Lasso_**, **_RandomForestRegressor_**, **_DecisionTreeRegressor_**,**_LinearRegressor_**, **_Ridge_**, **_GradientBoostingRegressor_**, **_XGBRegressor_**, and **_KNeighborsRegressor_**. After spot testing each model with ```Cross-validation``` evaluating each model in turn, I chose the three highest-score algorithms producing the least *mean squared error*, (*MSE*) as our metric of the problem:\n",
    "\n",
    "* **_Ridge_**\n",
    "* **_GradientBoostingRegressor_**\n",
    "* **_XGBRegressor_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can find the most important features in predicting salaries. Since _RandomizedSearch_ \n",
    "* does a good job finding near-optimal hyper-parameters over a very large search space relatively quickly, \n",
    "* doesn't suffer from the same exponential scaling problem as _GridSearch,_ and \n",
    "* does not test every possible combination of parameters,  \n",
    "\n",
    "I am using it first to extract some overall good patameter combination for later fine-tuning the results using _GridSearch_. To do so, here is the proceedure:\n",
    "\n",
    "* Determining Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data.\n",
    "* Parameter setting that gave the best results on the hold out data.\n",
    "* Mean cross-validated score of the best_estimator\n",
    "* Return the score on the validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 7 Engineer features  ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will cycle through creating features, tuning models, and training/validing models (steps 7-9) until I've reached the efficacy goal:\n",
    "\n",
    "#### Our metric is chosen to be MSE and our goal is:\n",
    " - <360 for entry-level data science roles\n",
    " - <320 for senior data science roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 8 Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import randomized_search as rs\n",
    "\n",
    "# initializing the parameter combinations for RandomizedSearch\n",
    "for model, distribution in [(Ridge(), dict(alpha=uniform(loc=0.001, scale=20.001))), \n",
    "                            (GradientBoostingRegressor(), dict(learning_rate=uniform(loc=0, scale=1.0), \n",
    "                                                               max_features=randint(low=2, high=21),\n",
    "                                                               max_depth=randint(low=2, high=10))), \n",
    "                            (XGBRegressor(), dict(learning_rate=uniform(loc=0, scale=1.0), \n",
    "                                                  max_depth=randint(low=2, high=10),       \n",
    "                                                  n_estimators=randint(low=10, high=101)))]:\n",
    "    \n",
    "    rs.randomized_search(model, distribution, features_train, target_train, features_validation, target_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 9 Test models ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an idea of the overall ranges of best parameters, we can do a finer search by using _GridSearchCV_ instead of _RandomizedSearchCV_ as well as preprocessing our data using _polynomialFeatures_ of degree 2 for **_Ridge_** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, param_grid in [(Ridge(), {'polynomialfeatures__degree': [1, 2],\n",
    "                                     'ridge__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 1]}),\n",
    "                          (GradientBoostingRegressor(), {'polynomialfeatures__degree': [1],\n",
    "                                                         'gradientboostingregressor__learning_rate': [0.1, 0.2, 0.3, 0.4], \n",
    "                                                         'gradientboostingregressor__max_depth': [4, 5, 6]}),\n",
    "                          (XGBRegressor(), {'polynomialfeatures__degree': [1],\n",
    "                                            'xgbregressor__learning_rate': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8],\n",
    "                                            'xgbregressor__max_depth': [4, 5, 6]})]:\n",
    "    pipe = make_pipeline(PolynomialFeatures(interaction_only=True, include_bias=False), model)\n",
    "    \n",
    "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=kfold, n_jobs=6, scoring='neg_mean_squared_error')\n",
    "    grid.fit(features_train, target_train)\n",
    "   \n",
    "    print('model:', model)\n",
    "    # determine the best parameters trained on the whole training set for each model\n",
    "    print(\"Best parameters: {}\".format(grid.best_params_))\n",
    "    # evaluate how well the best found parameters generalize\n",
    "    print(\"Test-set score: {:.3f}\\n\\n\".format(-1*grid.score(features_validation, target_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 10 Select best model  ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the introduction of interaction-terms of a 2nd degree polynomial to the list of features for a _Liear_ **_Ridge_** model is not as good as **_GradientBoostingRegressor_** or **_GBRegressor_**. So, I proceeded with the former given the _best parameters_ above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To differentiate possible levels a data scientist can have, these conditions should be met:\n",
    "* There are 4 levels: \"entry-level,\" \"junior,\" \"senior,\" and \"principal\" with the \"yearsExperience\" being inside the bins [0,2], [3,4], [5,9], and [10,24]. \n",
    "* A data science role should have at least a high school degree.\n",
    "* A data science role cannot have the value, \"JANITOR\" as its \"jobType\".\n",
    "\n",
    "Let's apply the best algorithm to these subsets of \"train\" dataset to see if the model is accurate enough for predicting the salaries for _entry-level_ and _senior_ datascience roles. Before then, however, I added four more features into \"train\" data, i.e. three 2nd-degree polynomials and one 3r-degree polynomial. The reason I thought these four would be enough is that usually salary is dictated by three important features: \"degree\", \"yearsExperience,\" and \"jobType\". So, I made products from these features to introduce new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_original = train_data_Engineered.copy()\n",
    "\n",
    "train_original['experience_degree'] = train_original['yearsExperience'] * train_original['degree']\n",
    "train_original['experience_jobType'] = train_original['yearsExperience'] * train_original['jobType']\n",
    "train_original['degree_jobType'] = train_original['degree'] * train_original['jobType']\n",
    "train_original['experience_degree_jobType'] = train_original['yearsExperience'] * train_original['degree'] * train_original['jobType']\n",
    "\n",
    "#taking salary \"target\" to the end of table\n",
    "Names = list(train_original.columns)\n",
    "target_feature, last_item = Names.index('salary'), Names.index(Names[-1])\n",
    "Names[target_feature], Names[last_item] = Names[last_item], Names[target_feature]\n",
    "train_original = train_original[Names]\n",
    "\n",
    "salary_features_final, salary_target_final = (train_original.values[:,:len(train_original.columns)-1], \n",
    "                                              train_original.values[:,len(train_original.columns)-1])\n",
    "\n",
    "features_train_final, features_validation_final, target_train_final, target_validation_final = train_test_split(\n",
    "    salary_features_final, salary_target_final, test_size=validation_size, random_state=seed)\n",
    "\n",
    "pipe_xgbr_final = make_pipeline(StandardScaler(with_mean=False), \n",
    "                                XGBRegressor(learning_rate=0.1, max_depth=4, n_estimators=500, n_jobs=6, random_state=0))\n",
    "cv_results_all = cross_val_score(pipe_xgbr_final, features_train_final, target_train_final, \n",
    "                                 cv=kfold, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "print(\"Modeling Algorithm = \", \"XGBRegressor\")\n",
    "print('{}: {:.1f} ({:.1f})'.format('all training set', -1*cv_results_all.mean(), cv_results_all.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best test set-score I had for the entire \"training\" dataset, i.e. before splitting the set into different levels based on the level of experience of individual data science roles. Now, using the same **_XGBRegressor_**, I will train the two subsets differently and will score the validation dataset for each level to see if I meet the required goal of the business problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_original['yearsExperience'].loc[train_original['yearsExperience'].between(0, 2, inclusive=True)] = 1 \n",
    "train_original['yearsExperience'].loc[train_original['yearsExperience'].between(3, 4, inclusive=True)] = 2\n",
    "train_original['yearsExperience'].loc[train_original['yearsExperience'].between(5, 9, inclusive=True)] = 3\n",
    "train_original['yearsExperience'].loc[train_original['yearsExperience'].between(10,24, inclusive=True)] = 4\n",
    "\n",
    "# separating entry-level and senior-level jobs for assessing the accuracy of our model\n",
    "train_original_entry_1, train_original_senior_1 = (train_original[(train_original['yearsExperience'] == 1)], \n",
    "                                                   train_original[(train_original['yearsExperience'] == 3)])\n",
    "\n",
    "train_original_entry, train_original_senior = (train_original_entry_1.drop(columns=['yearsExperience']), \n",
    "                                               train_original_senior_1.drop(columns=['yearsExperience']))\n",
    "\n",
    "salary_features_entry, salary_features_senior = (train_original_entry.values[:,:len(train_original_entry.columns)-1], \n",
    "                                                 train_original_senior.values[:,:len(train_original_senior.columns)-1])  \n",
    "salary_target_entry, salary_target_senior = (train_original_entry.values[:,len(train_original_entry.columns)-1], \n",
    "                                             train_original_senior.values[:,len(train_original_senior.columns)-1])\n",
    "\n",
    "# Train-Test-Split for entry-level subset of data\n",
    "features_train_entry, features_validation_entry, target_train_entry, target_validation_entry = train_test_split(\n",
    "    salary_features_entry, salary_target_entry, test_size=validation_size, random_state=seed)\n",
    "# Train-Test-Split for entry-level subset of data\n",
    "features_train_senior, features_validation_senior, target_train_senior, target_validation_senior = train_test_split(\n",
    "    salary_features_senior, salary_target_senior, test_size=validation_size, random_state=seed) \n",
    "\n",
    "# Cross-Validation scoring of entry-level roles\n",
    "cv_results_entry = cross_val_score(pipe_xgbr_final, features_train_entry, target_train_entry, \n",
    "                                   cv=kfold, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "# Cross-Validation scoring of senior-level roles\n",
    "cv_results_senior = cross_val_score(pipe_xgbr_final, features_train_senior, target_train_senior, \n",
    "                                    cv=kfold, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "print(\"Modeling Algorithm = \", \"XGBRegressor\")\n",
    "print('{}: {:.1f} ({:.1f})'.format('Entry-Level', -1*cv_results_entry.mean(), cv_results_entry.std()))\n",
    "print('{}: {:.1f} ({:.1f})\\n\\n'.format('Senior', -1*cv_results_senior.mean(), cv_results_senior.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that the goal is met (even better than our original goal of 360 for _entry-level_ and 320 for _senior_ data science roles), and we have the best parameters of **_XGBRegressor_** for the entire dataset, let's predict the salaries of the \"test\" data based on the best-fit model obtained earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - DEPLOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 11 Automate pipeline ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align \"train\" and \"test\" datasets\n",
    "test_original = test_data_Engineered.copy()\n",
    "test_original['yearsExperience'].loc[test_original['yearsExperience'].between(0, 2, inclusive=True)] = 1 \n",
    "test_original['yearsExperience'].loc[test_original['yearsExperience'].between(3, 4, inclusive=True)] = 2\n",
    "test_original['yearsExperience'].loc[test_original['yearsExperience'].between(5, 9, inclusive=True)] = 3\n",
    "test_original['yearsExperience'].loc[test_original['yearsExperience'].between(10,24, inclusive=True)] = 4\n",
    "\n",
    "test_original['experience_degree'] = test_original['yearsExperience'] * test_original['degree']\n",
    "test_original['experience_jobType'] = test_original['yearsExperience'] * test_original['jobType']\n",
    "test_original['degree_jobType'] = test_original['degree'] * test_original['jobType']\n",
    "test_original['experience_degree_jobType'] = test_original['yearsExperience'] * test_original['degree'] * test_original['jobType']\n",
    "\n",
    "test_original['salary'] = 0\n",
    "test_original = test_original[train_original.columns]\n",
    "test_dataset = test_original.iloc[:, :-1].values\n",
    "\n",
    "pipe_xgbr_final.fit(salary_features_final, salary_target_final)\n",
    "predictions = np.rint(pipe_xgbr_final.predict(test_dataset))\n",
    "test['salary'] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am saving my prediction to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save your prediction to a csv file\n",
    "test.to_csv(path_or_buf='Predicted_Salaries.csv', columns=None, header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 12 Deploy solution ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, let's save little more visualizations and summary of the predictions and feature importances which will be extremely useful to business stakeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.Series(pipe_xgbr_final[1].feature_importances_, index=train_original.iloc[:, :-1].columns)\n",
    "#print(feature_imrtances)\n",
    "feature_importances.sort_values(inplace=True)\n",
    "ax = feature_importances.plot(kind='barh', figsize=(10,10), \n",
    "                              xlim=[0, round(pipe_xgbr_final[1].feature_importances_.max(), 1)], \n",
    "                              ylim=[-1, n_features], \n",
    "                              label=pipe_xgbr_final[1].__class__.__name__)\n",
    "my_x_label = ax.set_xlabel(\"Feature importance\")\n",
    "my_y_label = ax.set_ylabel(\"Feature\")\n",
    "ax.get_figure().savefig(\"images/Feature_Importances_all.png\", dpi=None, facecolor='w', edgecolor='w', \n",
    "            orientation='portrait', papertype=None, format=None,\n",
    "            transparent=False, bbox_inches='tight', pad_inches=0,\n",
    "            frameon=None, metadata=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create combined feature importances as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import graph_feature_importances as gfi\n",
    "categorical_variables = [\"major\", \"industry\"]\n",
    "gfi.graph_feature_importances(pipe_xgbr_final[1], train_original.columns, summarized_columns=categorical_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from engineered features, i.e. _degree\\*jobType_ ,  _yearsExperience\\*jobType_ , _yearsExperience\\*degree_ , and  _yearsExperience\\*degree*jobType_ which are all added and seems to be important, the order of importance among original features seems to be _industy_ > _jobType_ > _major_ > _yearsExperience_ > _degree_. This only means that these features are important predictive but it does not say how they are important. While _feature importance_ shows what variables most affect predictions, _partial dependence_ plots show how a feature affects predictions. A few items are worth pointing out as one interprets this plot. The y axis is interpreted as change in the prediction from what it would be predicted at the baseline or leftmost value. A blue shaded area indicates level of confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_X_colns = [\"jobType\", \"degree\", \"yearsExperience\", \"milesFromMetropolis\"]\n",
    "salary_X = train_original[salary_X_colns]\n",
    "model = pipe_xgbr_final[1].fit(salary_X, train_original.iloc[:,-1:])\n",
    "\n",
    "h, ax18 = plt.subplots(figsize=(20, 5))\n",
    "my_title = ax18.set_title('Partial dependence of salary on numerical and ordinal features\\n'\n",
    "                          'for the Salary Prediction Project, with XGBRegressor', \n",
    "                          fontsize=18, pad=0)\n",
    "salary_plots = plot_partial_dependence(model, \n",
    "                                       X=salary_X, \n",
    "                                       features=[\"jobType\", \"degree\", \"yearsExperience\", \"milesFromMetropolis\"], \n",
    "                                       feature_names=salary_X_colns, \n",
    "                                       method='brute', n_cols=4, grid_resolution=20, n_jobs=-1, ax=ax18)\n",
    "\n",
    "plt.savefig(\"images/Scikit-Learn_Partial_Dependence_Plots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_features = [\"jobType\", \"degree\", \"yearsExperience\", \"milesFromMetropolis\"]\n",
    "for feat in list_features:\n",
    "    pdp_salary = pdp.pdp_isolate(model, \n",
    "                                 dataset=train_original, \n",
    "                                 model_features=list_features, feature=feat)\n",
    "    # generate plot\n",
    "    fig, axes = pdp.pdp_plot(pdp_isolate_out=pdp_salary, feature_name=feat, \n",
    "                             plot_pts_dist=True, figsize=(6, 4))\n",
    "\n",
    "    # save figure\n",
    "    plt.savefig('images/pdp_{}.png'.format(feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- 13 Measure efficacy ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll skip this step since we don't have the outcomes for the test data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
